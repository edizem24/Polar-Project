{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **POLAR PROJECT**"
      ],
      "metadata": {
        "id": "0D5JJSe1e7Ca"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul6ZCZyqerzS"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AmVtM3NJerzT"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from functools import reduce\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import tabulate\n",
        "from pylab import rcParams\n",
        "from scipy.stats import shapiro\n",
        "from statsmodels.graphics.gofplots import qqplot\n",
        "from statsmodels.stats.diagnostic import het_goldfeldquandt\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EqWeiHBderzV"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWul8nsXerzW"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uH4pW4g1erzX"
      },
      "outputs": [],
      "source": [
        "# Set figure size\n",
        "rcParams['figure.figsize'] = (4, 4)\n",
        "\n",
        "# Folder for images\n",
        "Path('img').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Nice float format\n",
        "pd.options.display.float_format = \"{:,.2f}\".format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpDtXseZerzX"
      },
      "source": [
        "# Data description\n",
        "\n",
        "Last year I purchased a Polar watch that tracks my vitals during workouts. I used the [Polar Flow](polar.flow.com) website to obtain a copy of my data. For privacy reasons I shall not be sharing the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "W-WTp-y0erzY"
      },
      "outputs": [],
      "source": [
        "path = './data/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5gb1OmeerzY"
      },
      "source": [
        "First, we create a list of files in the download."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "MbvhJlYSerzZ",
        "outputId": "040d2e40-a00d-4cbb-9cd6-fcaf2e84ba40"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './data/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-1443107943.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/'"
          ]
        }
      ],
      "source": [
        "files = [f for f in listdir(path) if isfile(join(path, f))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBS4m9fherzZ"
      },
      "source": [
        "We shall only consider files containing the string `'training-session'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "HpH8AahIerzZ",
        "outputId": "279e43a7-b2c2-444d-9ec3-e0ab24f92552"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'files' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-2973143641.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'training-session'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
          ]
        }
      ],
      "source": [
        "files = [f for f in files if 'training-session' in f]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0xfTqixerzZ"
      },
      "source": [
        "The number of files under consideration is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "75fi9vtEerza",
        "outputId": "d6c46c88-a75b-4747-a59a-d51cabee1091"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'files' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-7-2817292283.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
          ]
        }
      ],
      "source": [
        "len(files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcP9AoMXerza"
      },
      "source": [
        "We loop over each of the files and them to a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "rSa-gl4_erza",
        "outputId": "85534882-65ae-4282-eb2e-d1e7948c6bf8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'files' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-8-2050956125.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
          ]
        }
      ],
      "source": [
        "data = []\n",
        "\n",
        "for f in files:\n",
        "    with open(join(path, f)) as f:\n",
        "        d = json.load(f)\n",
        "        data.append(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgAwOmWVerza"
      },
      "source": [
        "We define a function to extract statistics about heart rate measured during the workouts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJTvkVmrerza"
      },
      "outputs": [],
      "source": [
        "quantiles = [0.01, 0.25, 0.5, 0.75, 0.99]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGZJgMX8erzb"
      },
      "outputs": [],
      "source": [
        "def extract_hr_info(workout, quantiles):\n",
        "\n",
        "    stats = {'heartRateAvg2': np.nan,\n",
        "             'heartRateStd': np.nan}\n",
        "\n",
        "    for q in quantiles:\n",
        "        stats[f'heartRateQ' + str(int(q * 100))] = np.nan\n",
        "\n",
        "    # Check if data exists\n",
        "    try:\n",
        "        heart_rates = workout['exercises'][0]['samples']['heartRate']\n",
        "    except KeyError:\n",
        "        return stats\n",
        "\n",
        "    # Loop over measurements\n",
        "    hr_data = []\n",
        "    for hr in heart_rates:\n",
        "\n",
        "        # Check if actually measured hr\n",
        "        if 'value' in hr:\n",
        "            hr_data.append(hr['value'])\n",
        "\n",
        "    stats['heartRateAvg2'] = np.mean(hr_data)\n",
        "    stats['heartRateStd'] = np.std(hr_data)\n",
        "\n",
        "    for q in quantiles:\n",
        "        stats[f'heartRateQ' + str(int(q * 100))] = np.quantile(hr_data, q)\n",
        "\n",
        "    return stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVtjDyL2erzb"
      },
      "source": [
        "We extract the relevant information from the items in the list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGKf4bjLerzb"
      },
      "outputs": [],
      "source": [
        "workouts = []\n",
        "\n",
        "for d in data:\n",
        "    basic = d['exercises'][0]\n",
        "    hr = extract_hr_info(workout=d,\n",
        "                         quantiles=quantiles)\n",
        "\n",
        "    workouts.append({**basic, **hr})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvmRvymKerzb"
      },
      "source": [
        "Finally we create a dataframe containing the workout information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fm6CBbj_erzb"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(workouts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX5MOPmQerzb"
      },
      "source": [
        "# Data structure\n",
        "\n",
        "We find the following columns in the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM9XT5X0erzb"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlcIYU5ierzb"
      },
      "source": [
        "We remove columns that containt data from features I do not use in my training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbxouMPLerzc"
      },
      "source": [
        "Due to privacy concerns I shan't be extracting longitudinal and latitudinal data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZR32gxIrerzc"
      },
      "outputs": [],
      "source": [
        "df = df.drop(['zones', 'samples', 'autoLaps',\n",
        "              'laps', 'latitude', 'longitude',\n",
        "              'ascent', 'descent'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "44PvebSZerzc"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_z7Ou6Ojerzc"
      },
      "source": [
        "# Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wEANpeterzc"
      },
      "source": [
        "The watch tracks different information for different workouts. For example when walking it tracks location but when walking on a treadmill it doesn't, hence there is quite a lot of missing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_c_ajJAerzc"
      },
      "outputs": [],
      "source": [
        "missing = (df.isna().sum() / df.shape[0] * 100)\n",
        "missing.name = 'Percent missing'\n",
        "missing = missing.to_frame()\n",
        "missing = missing.sort_values('Percent missing', ascending=False)\n",
        "missing = missing[missing['Percent missing'] > 0]\n",
        "missing = missing.reset_index()\n",
        "missing = missing.rename(columns={'index': 'Feature'})\n",
        "np.round(missing, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLhXmSZaerzc"
      },
      "source": [
        "# Transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2zer7W-erzc"
      },
      "source": [
        "We apply certain transforms to make the data easier to work with. First we convert strings to datetimes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ej2Hwwoeerzc"
      },
      "outputs": [],
      "source": [
        "df['startTime'] = pd.to_datetime(df['startTime'])\n",
        "df['stopTime'] = pd.to_datetime(df['stopTime'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ejyj8y21erzc"
      },
      "source": [
        "We calculate the total duration of each individual workout in minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "aCwkm39Kerzd"
      },
      "outputs": [],
      "source": [
        "df['totalTime'] = (df['stopTime'] - df['startTime'])\n",
        "df['totalTime'] = df['totalTime'].apply(lambda x: round(x.seconds / 60, 2))\n",
        "df.drop('duration', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJgWRBBZerzd"
      },
      "source": [
        "We extract maximum, average and minimum heart rate values from the `heartRate` column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTFPrviferzd"
      },
      "outputs": [],
      "source": [
        "df['heartRateMax'] = df['heartRate'].apply(lambda x: x['max'] if isinstance(x, dict) else np.nan)\n",
        "df['heartRateAvg'] = df['heartRate'].apply(lambda x: x['avg'] if isinstance(x, dict) else np.nan)\n",
        "df['heartRateMin'] = df['heartRate'].apply(lambda x: x['min'] if isinstance(x, dict) else np.nan)\n",
        "df.drop('heartRate', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxqQb9J0erzd"
      },
      "source": [
        "We assume that if there is no `distance` then the workout was indoors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1K7BP-fNerzi"
      },
      "outputs": [],
      "source": [
        "df['isInside'] = df['distance'].apply(lambda x: True if pd.isnull(x) else False)\n",
        "df = df.drop(['distance', 'speed'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZDM6pRperzj"
      },
      "source": [
        "We are going to map sports to different `activityType`'s. We will map strength training to `1` and cardiovascular work to `0`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9icNrJmwerzj"
      },
      "outputs": [],
      "source": [
        "def sport_to_activity_type(x):\n",
        "    if 'strength' in x.lower():\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BN_fKGhWerzj"
      },
      "outputs": [],
      "source": [
        "df['isStrength'] = df['sport'].apply(sport_to_activity_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBVaKPaserzj"
      },
      "outputs": [],
      "source": [
        "df['sport'] = df['sport'].apply(lambda x: x.lower())\n",
        "df['sport'] = pd.Categorical(df['sport'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-dgDLYyerzj"
      },
      "source": [
        "We extract a list of unique `sport` values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkCHAp4kerzj"
      },
      "outputs": [],
      "source": [
        "sports = sorted(list(df['sport'].unique()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVOJIS8Merzj"
      },
      "source": [
        "We reorder the alphabetically"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3V6Pdpu5erzj"
      },
      "outputs": [],
      "source": [
        "order = sorted(df.columns.to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZAB1c2Lerzk"
      },
      "outputs": [],
      "source": [
        "df = df[order]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMEI1WFOerzk"
      },
      "source": [
        "We check if there are any more `NaN`'s in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2dem5HNerzk"
      },
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daH0856xerzk"
      },
      "source": [
        "There is one row with `NaN`'s. This might due to my watch having little battery left to make the measurements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u--XjFFuerzk"
      },
      "outputs": [],
      "source": [
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XkqX1T1erzk"
      },
      "source": [
        "We proceed to sort the data with the latest workouts at the top of the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlKgIfJ_erzk"
      },
      "outputs": [],
      "source": [
        "sort_cols = ['startTime','startTime']\n",
        "df = df.sort_values(sort_cols, ascending=False)\n",
        "df = df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2_IG1nIerzk"
      },
      "source": [
        "We verify that the datatypes are correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jE_KUOwperzk"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjatX1tnerzl"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1kTPpoaerzl"
      },
      "source": [
        "# Data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dvw4VOierzl"
      },
      "source": [
        "Given that we have produced a clean dataset we can proceed to analyse a few aspects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyvYyxhferzl"
      },
      "source": [
        "## Time span"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhQYoz7Aerzl"
      },
      "source": [
        "The date of the first workout is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bJwoa7Nerzl"
      },
      "outputs": [],
      "source": [
        "str(df['startTime'].min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NupgBFTerzl"
      },
      "source": [
        "The date of the last workout is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPLW5sGcerzm"
      },
      "outputs": [],
      "source": [
        "str(df['startTime'].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF1QIZd5erzm"
      },
      "source": [
        "Workouts measured:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXvlobqAerzm"
      },
      "outputs": [],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzaYl3jkerzm"
      },
      "source": [
        "## Descriptive statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqZkVhaferzm"
      },
      "outputs": [],
      "source": [
        "df.drop('timezoneOffset', axis=1).describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRA0ATt2erzm"
      },
      "source": [
        "## Kilocalories burned in total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCo9hzt4erzn"
      },
      "source": [
        "First we count the total `kiloCalories` I burned during the period in question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-i2PUtqcerzn"
      },
      "outputs": [],
      "source": [
        "total_calories = df['kiloCalories'].sum()\n",
        "print(total_calories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuXqwczWerzn"
      },
      "source": [
        "We convert this number to kilograms of body fat.\n",
        "According to [this article](https://www.livestrong.com/article/304137-how-many-calories-per-kilogram-of-weight/) it equates to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsaKY9uFerzn"
      },
      "outputs": [],
      "source": [
        "def kcal_to_kg(x):\n",
        "    return round(x / 7700, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11c1vnaMerzn"
      },
      "outputs": [],
      "source": [
        "kcal_to_kg(total_calories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ksh8wKaerzn"
      },
      "source": [
        "## Kilocalories burned by sport"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2evCXrjerzn"
      },
      "outputs": [],
      "source": [
        "by_sport = df[['kiloCalories', 'sport']].groupby('sport', as_index=False)\n",
        "by_sport = by_sport.sum()\n",
        "by_sport['sport'] = by_sport['sport'].apply(lambda x: x.lower())\n",
        "by_sport['kiloCalories'] = by_sport['kiloCalories'].astype(int)\n",
        "by_sport = by_sport.rename(columns={'kiloCalories': 'Total kilocalories', 'sport': 'Sport'})\n",
        "by_sport = by_sport.sort_values('Total kilocalories', ascending=False)\n",
        "by_sport['Total kilograms'] = by_sport['Total kilocalories'].apply(kcal_to_kg)\n",
        "\n",
        "# by_sport = by_sport.style.background_gradient(cmap='YlGn', subset='Total kilograms')\n",
        "# by_sport = by_sport.set_precision(2)\n",
        "\n",
        "by_sport"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8c4AaDuerzn"
      },
      "source": [
        "## Kilocalories burned over time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOvJhT4merzo"
      },
      "source": [
        "Next we produce a plot of `kiloCalories` burned over a two month period in 2019. First we extract the relevant data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mN8J8STGerzo"
      },
      "outputs": [],
      "source": [
        "start = pd.to_datetime('2019-04-1')\n",
        "stop = pd.to_datetime('2019-06-1')\n",
        "\n",
        "daily = df[['startTime', 'kiloCalories']]\n",
        "mask = (daily['startTime'] >= start) & (daily['startTime'] < stop)\n",
        "daily = daily[mask]\n",
        "daily['startTime'] = daily['startTime'].dt.date\n",
        "daily = daily.groupby('startTime', as_index=False)\n",
        "daily = daily.sum()\n",
        "daily = daily.sort_values('startTime', ascending=False)\n",
        "daily['startTime'] = pd.to_datetime(daily['startTime'])\n",
        "daily = daily.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5pssvDserzo"
      },
      "source": [
        "We create a dataframe with all the dates to perform a left join and fill the `NaN`'s with zeroes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-O400rS-erzo"
      },
      "outputs": [],
      "source": [
        "dates = pd.date_range(start, stop)\n",
        "dates = dates.to_frame()\n",
        "dates = dates.reset_index(drop=True)\n",
        "dates.columns = ['startTime']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Kn3f3hAerzo"
      },
      "outputs": [],
      "source": [
        "daily = pd.merge(dates, daily, on='startTime', how='left')\n",
        "daily = daily.fillna(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52US59Yaerzo"
      },
      "source": [
        "Finally we produce the figure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "029QdnlSerzo"
      },
      "outputs": [],
      "source": [
        "width = 800\n",
        "height = 400\n",
        "dpi = 100\n",
        "\n",
        "plt.figure(figsize=(width/dpi, height/dpi))\n",
        "plt.plot(daily['startTime'], daily['kiloCalories'])\n",
        "\n",
        "plt.fill_between(x=daily['startTime'],\n",
        "                 y1=0,\n",
        "                 y2=daily['kiloCalories'],\n",
        "                 alpha=1/2)\n",
        "\n",
        "daily_avg = daily['kiloCalories'].mean()\n",
        "\n",
        "plt.hlines(xmin=daily['startTime'].min(),\n",
        "           xmax=daily['startTime'].max(),\n",
        "           y=daily_avg,\n",
        "           linestyle='dashed',\n",
        "           label=f'Daily average = {round(daily_avg)} kcal',\n",
        "           alpha=1/2)\n",
        "\n",
        "plt.title('Kilocalories burned over time', fontsize=18)\n",
        "plt.xticks(rotation=45, horizontalalignment='center')\n",
        "plt.xlim(daily['startTime'].min(), daily['startTime'].max())\n",
        "plt.ylim(0, daily['kiloCalories'].max() * 1.05)\n",
        "plt.ylabel('Kilocalories')\n",
        "plt.legend(loc='best')\n",
        "plt.tight_layout()\n",
        "plt.savefig('./img/kilocalories_ts.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9-_pTPGerzo"
      },
      "source": [
        "## Kilocalories by intensity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_QzxFfIerzp"
      },
      "outputs": [],
      "source": [
        "plt.scatter(df['heartRateQ1'], df['heartRateQ99'], c=df['kiloCalories'])\n",
        "plt.xlabel('0.01 quantile of heart rate (bpm)')\n",
        "plt.ylabel('0.99 quantile of heart rate (bpm)')\n",
        "\n",
        "cbar = plt.colorbar()\n",
        "cbar.set_label('Kilocalories', rotation=270)\n",
        "plt.savefig('./img/intensity_scatter.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBHt0x52erzp"
      },
      "source": [
        "## Workouts by sport"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD7srdyHerzp"
      },
      "source": [
        "We check how many workouts I completed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "empw3MHLerzp"
      },
      "outputs": [],
      "source": [
        "stats = df[['sport', 'startTime']]\n",
        "stats = stats.groupby(['sport'], as_index=False)\n",
        "stats = stats.count()\n",
        "stats = stats.rename(columns={'sport': 'Sport',\n",
        "                              'startTime': 'Count'})\n",
        "stats = stats.sort_values('Count', ascending=False)\n",
        "\n",
        "# stats = stats.style.background_gradient(cmap='YlGn', subset='Count')\n",
        "# stats = stats.set_precision(2)\n",
        "\n",
        "stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EklqCoAerzp"
      },
      "source": [
        "## By hour of day"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdUWUo0serzp"
      },
      "source": [
        "We count workouts by hour of day."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vp3_oHiKerzp"
      },
      "outputs": [],
      "source": [
        "by_hour = df[['startTime', 'sport']].copy()\n",
        "by_hour['startHour'] = by_hour['startTime'].dt.hour\n",
        "by_hour = by_hour.drop('startTime', axis=1)\n",
        "by_hour = by_hour.groupby('startHour', as_index=False)\n",
        "by_hour = by_hour.count()\n",
        "\n",
        "all_hours = pd.DataFrame(range(0, 24), columns=['startHour'])\n",
        "\n",
        "by_hour = pd.merge(all_hours, by_hour, how='left')\n",
        "by_hour = by_hour.fillna(0)\n",
        "by_hour = by_hour.sort_values('startHour')\n",
        "by_hour = by_hour.rename(columns={'startHour': 'Hour of day',\n",
        "                                 'sport': 'Total workouts'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Grx0N9pXerzp"
      },
      "outputs": [],
      "source": [
        "plt.bar(by_hour['Hour of day'], by_hour['Total workouts'])\n",
        "plt.ylabel('Number of workouts')\n",
        "plt.xlabel('Hour of day')\n",
        "plt.tight_layout()\n",
        "plt.savefig('./img/workouts_by_hour_of_day.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoTV2WbJerzp"
      },
      "source": [
        "## By day of week"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMFGizPZerzp"
      },
      "source": [
        "We count workouts by day of week."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "JqwRay0terzq"
      },
      "outputs": [],
      "source": [
        "by_day = df[['startTime', 'sport']].copy()\n",
        "by_day['Day of week'] = pd.to_datetime(by_day['startTime']).dt.day_name()\n",
        "by_day['Day number'] = pd.to_datetime(by_day['startTime']).dt.dayofweek\n",
        "by_day = by_day.groupby(['Day of week', 'Day number'], as_index=False)\n",
        "by_day = by_day.count()\n",
        "by_day = by_day.drop('startTime', axis=1)\n",
        "by_day = by_day.sort_values('Day number')\n",
        "by_day = by_day.rename(columns={'sport': 'Total Workouts'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5NVE45serzq"
      },
      "outputs": [],
      "source": [
        "plt.bar(by_day['Day of week'], by_day['Total Workouts'])\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel('Number of workouts')\n",
        "plt.savefig('./img/workouts_by_day_of_week.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdTljmoberzq"
      },
      "source": [
        "## Scatter plot of walks data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmtXldaqerzq"
      },
      "source": [
        "We plot `totalTime` versus `kiloCalories`. As can be seen their seems to exist a linear relationship between the two."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRiQxIyHerzq"
      },
      "outputs": [],
      "source": [
        "walking = df[df['sport'] == 'walking']\n",
        "plt.scatter(walking['totalTime'], walking['kiloCalories'], s=2)\n",
        "plt.xlabel('Duration (minutes)')\n",
        "plt.ylabel('Kilocalories')\n",
        "plt.savefig('./img/walks_kilocalories_vs_time.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TysEjNqVerzq"
      },
      "source": [
        "We plot `heartRateAvg` against `kiloCalories`. Again we see a linear relationship although there are a couple of outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XalM8aUDerzq"
      },
      "outputs": [],
      "source": [
        "walking = df[df['sport'] == 'walking']\n",
        "plt.scatter(walking['heartRateAvg'], walking['kiloCalories'], s=2)\n",
        "plt.ylabel('Kilocalories')\n",
        "plt.xlabel('Average HR (bpm)')\n",
        "plt.savefig('./img/walks_kilocalories_vs_avg_hr.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WyfPjRLerzq"
      },
      "source": [
        "# Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd9MuAZ-erzq"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv87W2MQerzr"
      },
      "source": [
        "Now we proceed to build a regression model to predict `kiloCalories` burned during a workout. First we create a subset of the original data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4gQYF0Cerzr"
      },
      "outputs": [],
      "source": [
        "reg_df = df[['kiloCalories', 'totalTime',\n",
        "             'heartRateQ99', 'isStrength', 'sport']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXNjqBhXerzr"
      },
      "outputs": [],
      "source": [
        "reg_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVW-Vtgjerzr"
      },
      "source": [
        "We remove the rows where `sport` is `running` because there were only two workouts recorded during the period in question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGjqx1gAerzr"
      },
      "outputs": [],
      "source": [
        "reg_df = reg_df[reg_df['sport'] != 'running']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hMBmVV3erzr"
      },
      "source": [
        "### Outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwUEYNi9erzr"
      },
      "source": [
        "The data is cleansed of outliers using interquartile range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4X5mKR_Perzr"
      },
      "outputs": [],
      "source": [
        "def is_outlier_iqr(series, k=1.5):\n",
        "    \"\"\"\n",
        "    Check if value is an outlier\n",
        "    using interquartile range.\n",
        "    \"\"\"\n",
        "\n",
        "    q1 = series.quantile(0.25)\n",
        "    q3 = series.quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    is_outlier = (series <= q1 - k * iqr) | (q3 + k * iqr <= series)\n",
        "\n",
        "    return is_outlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noE0JtfNerzr"
      },
      "outputs": [],
      "source": [
        "time_mask = is_outlier_iqr(series=reg_df['totalTime'])\n",
        "kcal_mask = is_outlier_iqr(series=reg_df['kiloCalories'])\n",
        "hr_mask = is_outlier_iqr(series=reg_df['heartRateQ99'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pj4Te4d_erzr"
      },
      "outputs": [],
      "source": [
        "reg_df = reg_df[~(time_mask | kcal_mask | hr_mask)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG7SHucmerzr"
      },
      "source": [
        "## Histograms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtiSHwo3erzr"
      },
      "source": [
        "We proceed to visualize histograms of each of the variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3iZUbTZerzs"
      },
      "outputs": [],
      "source": [
        "plt.hist(reg_df['kiloCalories'], bins=30)\n",
        "plt.xlabel('Kilocalories')\n",
        "plt.ylabel('Frequency')\n",
        "plt.savefig('./img/kilocalories_histogram.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bXlE2G2erzs"
      },
      "outputs": [],
      "source": [
        "plt.hist(reg_df['totalTime'], bins=30)\n",
        "plt.xlabel('Duration (minutes)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.savefig('./img/duration_histogram.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbkc9xBperzs"
      },
      "outputs": [],
      "source": [
        "plt.hist(reg_df['heartRateQ99'], bins=30)\n",
        "plt.xlabel('0.99 quantile of heart rate (bpm)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.savefig('./img/q99_hr_histogram.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMfCkaNQerzs"
      },
      "source": [
        "## Scatter plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9l2mPboerzs"
      },
      "source": [
        "The plot below gives reason to suspect a linear relationship between `kiloCalories` and `totalTime`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UE0aiQB7erzs"
      },
      "outputs": [],
      "source": [
        "for val in [False, True]:\n",
        "    tmp = reg_df[reg_df['isStrength'] == val]\n",
        "    plt.scatter(tmp['totalTime'],\n",
        "                tmp['kiloCalories'],\n",
        "                s=3,\n",
        "                label=val)\n",
        "\n",
        "plt.xlabel('Time (minutes)')\n",
        "plt.ylabel('Kilocalories')\n",
        "plt.legend(title='isStrength', loc='best')\n",
        "plt.tight_layout()\n",
        "plt.savefig('./img/time_vs_kilocalories_scatter_by_strength.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWM6Hy0Perzs"
      },
      "outputs": [],
      "source": [
        "for val in [False, True]:\n",
        "    tmp = reg_df[reg_df['isStrength'] == val]\n",
        "    plt.scatter(tmp['heartRateQ99'],\n",
        "                tmp['kiloCalories'],\n",
        "                s=3,\n",
        "                label=val)\n",
        "\n",
        "plt.xlabel('0.99 quantile of heart rate (bpm)')\n",
        "plt.ylabel('Kilocalories')\n",
        "plt.legend(title='isStrength', loc='best')\n",
        "plt.savefig('./img/99q_hr_vs_kilocalories_scatter_by_strength.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z29RE7aDerzs"
      },
      "outputs": [],
      "source": [
        "plt.scatter(reg_df['isStrength'] + np.random.normal(scale=1/20, size=len(reg_df)),\n",
        "            reg_df['kiloCalories'], s=3)\n",
        "\n",
        "plt.ylabel('Kilocalories')\n",
        "plt.xticks(ticks=[0, 1], labels=['Cardio', 'Strength'])\n",
        "plt.savefig('./img/is_strength_vs_kilocalories_jitter.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYAQ235werzs"
      },
      "outputs": [],
      "source": [
        "plt.scatter(reg_df['isStrength'] + np.random.normal(scale=1/20, size=len(reg_df)),\n",
        "            reg_df['heartRateQ99'], s=3)\n",
        "\n",
        "plt.ylabel('0.99 quantile of heart rate (bpm)')\n",
        "plt.xticks(ticks=[0, 1], labels=['Cardio', 'Strength'])\n",
        "plt.savefig('./img/is_strength_vs_99q_hr_scatter.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "el6WJtITerzt"
      },
      "outputs": [],
      "source": [
        "plt.scatter(reg_df['isStrength'] + np.random.normal(scale=1/20, size=len(reg_df)),\n",
        "            reg_df['totalTime'], s=3)\n",
        "\n",
        "plt.ylabel('Time (minutes)')\n",
        "plt.xticks(ticks=[0, 1], labels=['Cardio', 'Strength'])\n",
        "plt.savefig('./img/is_strength_vs_time_jitter.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsXvUDZrerzt"
      },
      "source": [
        "## Correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEIle6okerzt"
      },
      "source": [
        "We convert binary the feature `isStrength` to integers for the rest of the analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TP9g3Pderzt"
      },
      "outputs": [],
      "source": [
        "reg_df['isStrength'] = reg_df['isStrength'].astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIArsqS6erzt"
      },
      "source": [
        "We inspect the correlation matrix to check for multicollinearity. It should be noted that the correlation between `kiloCalories` and `totalTime` is quite high and this to be expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcg4ydpBerzt"
      },
      "outputs": [],
      "source": [
        "C = reg_df.corr(method='pearson')\n",
        "# C = C.style.background_gradient(cmap='YlGn')\n",
        "# C = C.set_precision(2)\n",
        "C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amI-dOnAerzt"
      },
      "source": [
        "## Multicollinearity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW8TBkwQerzu"
      },
      "source": [
        "We inspect the respect variance inflation factors and are happy to see that all are below 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFkn9D_qerzu"
      },
      "outputs": [],
      "source": [
        "tmp = reg_df.drop(['kiloCalories', 'sport'], axis=1)\n",
        "\n",
        "vifs = []\n",
        "for i in range(tmp.shape[1]):\n",
        "    vif = variance_inflation_factor(tmp.to_numpy(), i)\n",
        "    vifs.append(round(vif, 2))\n",
        "\n",
        "vifs = pd.DataFrame(vifs, index=tmp.columns, columns=['VIF'])\n",
        "vifs = vifs.sort_values('VIF', ascending=False)\n",
        "vifs = vifs.reset_index()\n",
        "vifs = vifs.rename(columns={'index': 'Variable'})\n",
        "\n",
        "# vifs = vifs.style.background_gradient(cmap='OrRd')\n",
        "# vifs = vifs.set_precision(2)\n",
        "\n",
        "vifs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eOU4WdNerzu"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykAmAzGeerzu"
      },
      "source": [
        "Before the actual modelling we prepare a function to calculate `RMSE` to compare models and extract the true `kiloCalories` into a separate array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cuRvBsKerzu"
      },
      "outputs": [],
      "source": [
        "y_true = reg_df['kiloCalories'].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vqD4yi9erzu"
      },
      "outputs": [],
      "source": [
        "def calc_rmse(y_true, y_pred):\n",
        "    x = np.sqrt(np.mean(np.power(y_true - y_pred, 2)))\n",
        "    return round(x, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXCGn4UJerzv"
      },
      "outputs": [],
      "source": [
        "all_results = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HTXtzRUerzv"
      },
      "source": [
        "### Time only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PIBQohgerzv"
      },
      "source": [
        "We start the modelling section of by building the simplest model that comes to mind: predict `kiloCalories` using `totalTime`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "VMK9KGQNerzv"
      },
      "outputs": [],
      "source": [
        "formula = 'kiloCalories ~ totalTime'\n",
        "mdl_time = smf.ols(formula=formula, data=reg_df)\n",
        "mdl_time = mdl_time.fit()\n",
        "mdl_time.summary2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GZ4pLn_erzv"
      },
      "outputs": [],
      "source": [
        "y_pred = mdl_time.predict(reg_df)\n",
        "rmse = calc_rmse(y_pred, y_true)\n",
        "all_results.append((rmse, formula))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rto-RmOkerzv"
      },
      "outputs": [],
      "source": [
        "print(rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfo26HB_erzw"
      },
      "source": [
        "### By sport"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnYQZVByerzw"
      },
      "source": [
        "The next regression we are going to do will be univariate regression separately for each sport, this will help us answer the question which sport is the most effective at burning calories during a workout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Se9_KeBxerzw"
      },
      "outputs": [],
      "source": [
        "all_sports = sorted(reg_df['sport'].unique())\n",
        "reg_sports_res = []\n",
        "\n",
        "# For all sport do simple linear regression\n",
        "for sport in all_sports:\n",
        "    tmp = reg_df[reg_df['sport'] == sport]\n",
        "    formula = 'kiloCalories ~ totalTime'\n",
        "    mdl_sport = smf.ols(formula=formula, data=tmp)\n",
        "    mdl_sport = mdl_sport.fit()\n",
        "    sport_stats = [formula, sport] + list(mdl_sport.params) + [mdl_sport.rsquared]\n",
        "    reg_sports_res.append(sport_stats)\n",
        "\n",
        "cols = ['Formula', 'Sport', 'Intercept', 'Slope', 'R squared']\n",
        "\n",
        "reg_sports_res = pd.DataFrame(reg_sports_res, columns=cols)\n",
        "reg_sports_res = reg_sports_res.sort_values(['Slope'], ascending=False)\n",
        "reg_sports_res = reg_sports_res.reset_index(drop=True)\n",
        "\n",
        "readme_df = reg_sports_res.copy().round(2)\n",
        "\n",
        "# reg_sports_res = reg_sports_res.style.background_gradient(cmap='YlGn', subset='Slope')\n",
        "# reg_sports_res = reg_sports_res.set_precision(2)\n",
        "\n",
        "reg_sports_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRno87PZerzw"
      },
      "source": [
        "## Time and heart rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqSc8heSerzw"
      },
      "source": [
        "We try to enhance the model by adding `heartRateQ99`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vf0G9tLlerzw"
      },
      "outputs": [],
      "source": [
        "formula = 'kiloCalories ~ totalTime + heartRateQ99'\n",
        "mdl_time_and_hr = smf.ols(formula=formula, data=reg_df)\n",
        "mdl_time_and_hr = mdl_time_and_hr.fit()\n",
        "mdl_time_and_hr.summary2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-bxbrkcerzw"
      },
      "outputs": [],
      "source": [
        "y_pred = mdl_time_and_hr.predict(reg_df)\n",
        "rmse = calc_rmse(y_pred, y_true)\n",
        "all_results.append((rmse, formula))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LRU8wIgerzx"
      },
      "outputs": [],
      "source": [
        "print(rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXVcCb9Verzx"
      },
      "source": [
        "## Time with random effects by workout type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "NC69p7b0erzx"
      },
      "outputs": [],
      "source": [
        "formula = 'kiloCalories ~ totalTime + heartRateQ99'\n",
        "re_formula = ' ~ totalTime'\n",
        "group = 'isStrength'\n",
        "\n",
        "mdl_time_with_hr_re = smf.mixedlm(formula=formula,\n",
        "                  data=reg_df,\n",
        "                  groups=reg_df[group],\n",
        "                  re_formula=re_formula)\n",
        "\n",
        "mdl_time_with_hr_re = mdl_time_with_hr_re.fit(method='lbfgs')\n",
        "mdl_time_with_hr_re.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxJ1m8vYerzx"
      },
      "outputs": [],
      "source": [
        "y_pred = mdl_time_with_hr_re.predict(reg_df)\n",
        "rmse = calc_rmse(y_pred, y_true)\n",
        "all_results.append((rmse, formula, re_formula, group))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzHZB4tAerzx"
      },
      "outputs": [],
      "source": [
        "print(rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqAD0naXerzx"
      },
      "source": [
        "## Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTAxIpI4erzx"
      },
      "source": [
        "We compare the linear models created earlier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Wa5x_mhFerzx"
      },
      "outputs": [],
      "source": [
        "comp_df = pd.DataFrame(all_results, columns=['RMSE', 'Formula', 'Random effects', 'Groups'])\n",
        "comp_df = comp_df.sort_values('RMSE')\n",
        "\n",
        "# comp_df = comp_df.style.background_gradient(cmap='OrRd', subset='RMSE')\n",
        "# comp_df = comp_df.set_precision(2)\n",
        "\n",
        "comp_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WeqXKbNerzy"
      },
      "source": [
        "For further evaluation we choose the random effects model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyQDYo5eerzy"
      },
      "outputs": [],
      "source": [
        "mdl = mdl_time_with_hr_re\n",
        "residuals = mdl_time_with_hr_re.resid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz0faUcierzy"
      },
      "source": [
        "### Visual inspection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QuJZG1Perzy"
      },
      "source": [
        "We proceed to inspect the residuals of the model. First we view the histogram of the residuals. It can be seen that it looks normal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YudEgBDlerzy"
      },
      "outputs": [],
      "source": [
        "plt.hist(residuals)\n",
        "plt.ylabel('Frequency')\n",
        "plt.xlabel('Residuals')\n",
        "plt.savefig('./img/mdl_residuals.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBNgYeSherzy"
      },
      "source": [
        "The next plot is a qqplot created to visually inspect the normality of the residuals. We see 3 nasty outliers in the top right corner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "BZVtDNAierzy"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "ax = plt.gca()\n",
        "\n",
        "qqplot(data=mdl.resid,\n",
        "       ax=ax,\n",
        "       color='#1f77b4',\n",
        "       markersize=3,\n",
        "       line='45',\n",
        "       fit=True,\n",
        "       alpha=1/2)\n",
        "\n",
        "plt.savefig('./img/mdl_qq.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwqlNLcLerzy"
      },
      "source": [
        "The third plot we make is a plot of the standardized residuals to check for homoskedasticity. Again we see the same outliers as on the plot above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ggDH1zwerzz"
      },
      "outputs": [],
      "source": [
        "residuals_std = np.abs((residuals - np.mean(residuals)) / np.std(residuals))\n",
        "plt.plot(residuals_std, 'o', markersize=2)\n",
        "plt.xlabel('Observation')\n",
        "plt.ylabel('Standardized residuals')\n",
        "plt.savefig('./img/mdl_residuals_std.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nsAs1dqerzz"
      },
      "source": [
        "Finally we compare the predicted `kiloCalories` with the actual values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gPuf21Zerzz"
      },
      "outputs": [],
      "source": [
        "y_pred = mdl.predict(reg_df)\n",
        "y_pred = y_pred.to_numpy().reshape(len(y_pred))\n",
        "\n",
        "m = np.min(np.hstack([y_true, y_pred]))\n",
        "M = np.max(np.hstack([y_true, y_pred]))\n",
        "\n",
        "x = np.linspace(m, M, len(y_pred))\n",
        "plt.plot(y_true, y_pred, 'o', markersize=2)\n",
        "plt.plot(x,x, alpha=3/4)\n",
        "plt.ylabel('Predicted')\n",
        "plt.xlabel('Actual')\n",
        "plt.tight_layout()\n",
        "plt.savefig('./img/mdl_predicted_vs_actual.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktLLCfoderzz"
      },
      "source": [
        "The next step is to take a look at the data points with the biggest error. As can be seen the model has issues predicting strength training workouts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ztgaCfRerzz"
      },
      "outputs": [],
      "source": [
        "errors = reg_df.copy()\n",
        "errors['kiloCaloriesPredicted'] = mdl.predict(reg_df)\n",
        "\n",
        "errors['error'] = np.abs(errors['kiloCalories'] - errors['kiloCaloriesPredicted'])\n",
        "\n",
        "errors = errors.sort_values('error', ascending=False)\n",
        "errors = errors.reset_index(drop=True)\n",
        "\n",
        "order = ['kiloCaloriesPredicted',\n",
        "         'kiloCalories',\n",
        "         'error',\n",
        "         'totalTime',\n",
        "         'isStrength']\n",
        "\n",
        "errors = errors[order]\n",
        "\n",
        "errors = errors.head(5)\n",
        "\n",
        "errors = errors.style.background_gradient(cmap='OrRd', subset='error')\n",
        "errors = errors.set_precision(2)\n",
        "\n",
        "errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq1ITddXerzz"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ew4PWixierzz"
      },
      "outputs": [],
      "source": [
        "# Make table for README\n",
        "# print(tabulate.tabulate(by_sport.values, by_sport.columns, tablefmt=\"pipe\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQVnBwP-erzz"
      },
      "outputs": [],
      "source": [
        "# Make table for README\n",
        "# print(tabulate.tabulate(readme_df.values, readme_df.columns, tablefmt=\"pipe\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpAOyrXIerz0"
      },
      "source": [
        "* In this project I define a `workout` as each instance in time when my watch was recording me.\n",
        "\n",
        "* I downloaded data generated by my Polar watch that tracks `heart rate` and estimates burned `kilocalories` during workouts.\n",
        "\n",
        "* The data came in the form of `.json` files which were read, transformed and cleaned with `pandas`.\n",
        "\n",
        "* The clean dataset contains `283` workouts over a nearly one year period during which I burned roughly `12kg` of body fat.\n",
        "\n",
        "| Sport             |   Total kilocalories |   Total kilograms |\n",
        "|:------------------|---------------------:|------------------:|\n",
        "| walking           |                33080 |              4.3  |\n",
        "| strength_training |                31547 |              4.1  |\n",
        "| treadmill_running |                19825 |              2.57 |\n",
        "| cycling           |                 4029 |              0.52 |\n",
        "| running           |                  940 |              0.12 |\n",
        "\n",
        "* The timing of my workouts appears to follow a `bimodal distribution` with peaks at `12:00` and `20:00`.\n",
        "\n",
        "<!-- ![image](https://github.com/besiobu/data-science-portfolio/blob/master/polar/img/workouts_by_hour_of_day.png) -->\n",
        "\n",
        "* After further transforming the data, I find that the `duration` of a workout and `kilocalorie`'s burned have a `0.92` correlation.\n",
        "\n",
        "<!-- ![image](https://github.com/besiobu/data-science-portfolio/blob/master/polar/img/time_vs_kilocalories_scatter_by_strength.png) -->\n",
        "\n",
        "* Several linear regressions were performed.\n",
        "\n",
        "* `kilocalories ~ duration` on the entire dataset achieved `R^2 = 0.85` and `RMSE = 79`.\n",
        "\n",
        "* Regressions were performed on subsets of the data, specifically by sport - the highest slope is `10.14 kiloCalories` per minute.\n",
        "\n",
        "| Formula                  | Sport             |   Intercept |   Slope |   R squared |\n",
        "|:-------------------------|:------------------|------------:|--------:|------------:|\n",
        "| kilo_calories ~ total_time | treadmill_running |      -21.23 |   10.14 |        0.96 |\n",
        "| kilo_calories ~ total_time | cycling           |       -9.73 |    7.44 |        0.98 |\n",
        "| kilo_calories ~ total_time | walking           |       12.59 |    6.95 |        0.82 |\n",
        "| kilo_calories ~ total_time | strength_training |      -12.73 |    6.76 |        0.44 |\n",
        "\n",
        "* A `linear mixed model with random effects` was created and validated. It achieved a `RMSE = 61` and normal looking residuals.\n",
        "\n",
        "<!-- ![image](https://github.com/besiobu/data-science-portfolio/blob/master/polar/img/mdl_predicted_vs_actual.png) -->\n",
        "\n",
        "* The biggest `errors` made by the `mixed model` was on `strength training` data points."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}